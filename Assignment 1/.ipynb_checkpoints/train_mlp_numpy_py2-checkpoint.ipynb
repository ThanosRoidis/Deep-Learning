{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements training and evaluation of a multi-layer perceptron in NumPy.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from mlp_numpy import MLP\n",
    "import cifar10_utils_py2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default constants\n",
    "LEARNING_RATE_DEFAULT = 2e-3\n",
    "WEIGHT_REGULARIZER_STRENGTH_DEFAULT = 0.\n",
    "WEIGHT_INITIALIZATION_SCALE_DEFAULT = 1e-4\n",
    "BATCH_SIZE_DEFAULT = 200\n",
    "MAX_STEPS_DEFAULT = 1500\n",
    "DNN_HIDDEN_UNITS_DEFAULT = '100'\n",
    "\n",
    "# Directory in which cifar data is saved\n",
    "DATA_DIR_DEFAULT = './cifar10/cifar-10-batches-py'\n",
    "LOG_DIR = './logs/cifar10/mlp_numpy/'\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_init_scale : 0.0001\n",
      "data_dir : ./cifar10/cifar-10-batches-py\n",
      "learning_rate : 0.002\n",
      "batch_size : 200\n",
      "weight_reg_strength : 0.0\n",
      "dnn_hidden_units : 100\n",
      "max_steps : 1500\n",
      "lapack_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "blas_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "openblas_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "blis_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_lapack_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "lapack_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "blas_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "None\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './logs/cifar10/mlp_numpy/mlp_numpy_20171111-1436/flags.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8d098bad637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b8d098bad637>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m#   print(layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b8d098bad637>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#SAVE FLAGS TO A FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLOG_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'mlp_numpy_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'flags.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './logs/cifar10/mlp_numpy/mlp_numpy_20171111-1436/flags.txt'"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Performs training and evaluation of MLP model. Evaluate your model on the whole test set each 100 iterations.\n",
    "    \"\"\"\n",
    "    ### DO NOT CHANGE SEEDS!\n",
    "    # Set the random seeds for reproducibility\n",
    "    np.random.seed(42)\n",
    " \n",
    "\n",
    "    # FLAGS.dnn_hidden_units = '100'\n",
    "    ## Prepare all functions\n",
    "    # Get number of units in each hidden layer specified in the string such as 100,100\n",
    "    if FLAGS.dnn_hidden_units:\n",
    "        dnn_hidden_units = FLAGS.dnn_hidden_units.split(\",\")\n",
    "        dnn_hidden_units = [int(dnn_hidden_unit_) for dnn_hidden_unit_ in dnn_hidden_units]\n",
    "    else:\n",
    "        dnn_hidden_units = []\n",
    "\n",
    "    train_cifar = True\n",
    "\n",
    "    if train_cifar:\n",
    "        dataset = cifar10_utils_py2.get_cifar10(FLAGS.data_dir)\n",
    "        n_input = 3072\n",
    "        n_classes = 10\n",
    "        norm_const = 1\n",
    "    else:\n",
    "        dataset = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "        n_input = 784\n",
    "        n_classes = 10\n",
    "        norm_const = 1\n",
    "        \n",
    "    #SAVE FLAGS TO A FILE\n",
    "    model_folder = LOG_DIR + 'mlp_numpy_' + time.strftime(\"%Y%m%d-%H%M\") + '/'\n",
    "    file = open(model_folder + 'flags.txt', 'w') \n",
    "    \n",
    "    for key, value in vars(FLAGS).items():\n",
    "        file.write(key + ' : ' + str(value))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    test_results = []\n",
    "\n",
    "\n",
    "#   FLAGS.weight_reg_strength = 0.001\n",
    "#   FLAGS.learning_rate = 0.1\n",
    "  # FLAGS.max_steps = 10000\n",
    "\n",
    "    mlp = MLP(n_input, dnn_hidden_units, n_classes,\n",
    "            weight_decay=FLAGS.weight_reg_strength,\n",
    "            weight_scale=FLAGS.weight_init_scale)\n",
    "\n",
    "    np.set_printoptions(threshold= np.nan)\n",
    "\n",
    "    for step in range(FLAGS.max_steps):\n",
    "        x, y = dataset.train.next_batch(FLAGS.batch_size)\n",
    "        x = np.reshape(x, (-1, n_input))  / norm_const\n",
    "\n",
    "        logits = mlp.inference(x)\n",
    "\n",
    "\n",
    "        loss, full_loss = mlp.loss(logits, y)\n",
    "        mlp.train_step(full_loss, FLAGS)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            x = dataset.test.images\n",
    "            x = np.reshape(x, (-1, n_input)) / norm_const\n",
    "            y = dataset.test.labels\n",
    "\n",
    "            logits = mlp.inference(x)\n",
    "            loss, full_loss = mlp.loss(logits, y)\n",
    "            acc =  mlp.accuracy(logits, y)\n",
    "            print('step %d: loss: %f, %f, acc: %f' % (step, loss, full_loss,acc))\n",
    "            \n",
    "            test_results.append((step, full_loss, acc)) \n",
    "\n",
    "    #Evaluate on test set after the training has finished\n",
    "    x = dataset.test.images / norm_const\n",
    "    x = np.reshape(x, (-1, n_input))\n",
    "    y = dataset.test.labels\n",
    "\n",
    "    logits = mlp.inference(x)\n",
    "    L, _ = mlp.loss(logits, y)\n",
    "    print('test:', L, mlp.accuracy(logits, y))\n",
    "    \n",
    "    test_results.append((FLAGS.max_steps, full_loss, acc))  \n",
    "    \n",
    "    #Save results to file\n",
    "    with open('results', 'wb') as fp:\n",
    "        pickle.dump(test_results, fp)\n",
    "\n",
    "\n",
    "\n",
    "def print_flags():\n",
    "  \"\"\"\n",
    "  Prints all entries in FLAGS variable.\n",
    "  \"\"\"\n",
    "  for key, value in vars(FLAGS).items():\n",
    "    print(key + ' : ' + str(value))\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "    # Print all Flags to confirm parameter settings\n",
    "    print_flags()\n",
    "\n",
    "    if not os.path.exists(FLAGS.data_dir):\n",
    "        os.makedirs(FLAGS.data_dir)\n",
    "\n",
    "    # Run the training operation\n",
    "\n",
    "    # for layer in range(5, 0, -1):\n",
    "    #   print(layer)\n",
    "    # return\n",
    "    train()\n",
    "\n",
    "  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dnn_hidden_units', type = str, default = DNN_HIDDEN_UNITS_DEFAULT,\n",
    "                  help='Comma separated list of number of units in each hidden layer')\n",
    "parser.add_argument('--learning_rate', type = float, default = LEARNING_RATE_DEFAULT,\n",
    "                  help='Learning rate')\n",
    "parser.add_argument('--max_steps', type = int, default = MAX_STEPS_DEFAULT,\n",
    "                  help='Number of steps to run trainer.')\n",
    "parser.add_argument('--batch_size', type = int, default = BATCH_SIZE_DEFAULT,\n",
    "                  help='Batch size to run trainer.')\n",
    "parser.add_argument('--weight_init_scale', type = float, default = WEIGHT_INITIALIZATION_SCALE_DEFAULT,\n",
    "                  help='Weight initialization scale (e.g. std of a Gaussian).')\n",
    "parser.add_argument('--weight_reg_strength', type = float, default = WEIGHT_REGULARIZER_STRENGTH_DEFAULT,\n",
    "                  help='Regularizer strength for weights of fully-connected layers.')\n",
    "parser.add_argument('--data_dir', type = str, default = DATA_DIR_DEFAULT,\n",
    "                  help='Directory for storing input data')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
